# ğŸ¤– TalentScout: LLM-Based Hiring Assistant Chatbot

TalentScout is a smart hiring assistant chatbot built with **Streamlit** and **Gemini Pro (Google AI)**.  
It helps simulate the first round of candidate screening by collecting their details and asking tech-specific questions based on their declared stack.

---

## ğŸš€ Features

- ğŸ“‹ Collects candidate info (name, email, experience, etc.)
- ğŸ’» Accepts tech stack input
- ğŸ§  Uses **Gemini Pro** to generate 3 relevant questions per tech skill
- ğŸ“ Lets candidates type answers for each generated question
- ğŸ’¾ Saves questions + answers + candidate info into a local `.json` file
- ğŸ” Allows re-generation of questions if needed
- ğŸ” Secures API key using a `.env` file
- ğŸ›¡ï¸ Handles reruns with `st.session_state` to preserve context
- ğŸ‘‹ Supports graceful exit using keywords like `exit`, `bye`, etc.

---

## ğŸ›  Tech Stack

| Component | Tool |
|----------|------|
| Frontend | Streamlit |
| LLM      | Gemini Pro (Google Generative AI) |
| Backend  | Python |
| Env Mgmt | python-dotenv |
| Storage  | Local JSON file |

---

## ğŸ§  Prompt Strategy

Each skill is processed with a prompt like:

> â€œGenerate 3 technical interview questions for a candidate skilled in Python.â€

The result from Gemini is stored alongside the candidateâ€™s typed answers.

---

## ğŸ“‚ Project Structure

talentscout_llm_chatbot/
â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ question_generator.py # LLM integration
â”œâ”€â”€ .env # API key (ignored in Git)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/ # Folder where JSON files are saved
â””â”€â”€ README.md

## âš™ï¸ Challenges & Solutions

| Challenge                               | Solution                                      |
| --------------------------------------- | --------------------------------------------- |
| Avoiding hardcoded API keys             | Used `.env` and `python-dotenv`               |
| Preserving multi-step conversation flow | Used `st.session_state`                       |
| Handling Geminiâ€™s response format       | Extracted `.text` and cleaned question string |
| Avoiding unnecessary re-generation      | Cached responses using session                |
| Handling unexpected input or exits      | Added `exit` command handling & fallbacks     |


## ğŸ™Œ Acknowledgements

- Streamlit
- Google Gemini Pro API
- python-dotenv
- Prompt Engineering Guide